<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="本篇博客主要讲述决策树的构建和剪枝，分析ID3、C4.5和CART的差异，最后附上决策树的实现，下面开始我的表演 一、决策树介绍定义5.1 (决策树) ：分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node )和叶结点(leaf node)。内部结点表示一个特征或属性，叶结点表示">
<meta property="og:type" content="website">
<meta property="og:title" content="决策树的理解与分析">
<meta property="og:url" content="http://yoursite.com/机器学习/决策树的理解与分析.html">
<meta property="og:site_name" content="YinHui&#39;s Bolg">
<meta property="og:description" content="本篇博客主要讲述决策树的构建和剪枝，分析ID3、C4.5和CART的差异，最后附上决策树的实现，下面开始我的表演 一、决策树介绍定义5.1 (决策树) ：分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node )和叶结点(leaf node)。内部结点表示一个特征或属性，叶结点表示">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509607721(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509608563(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509608634(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509608944(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509608972(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509608841(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509609130(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509609252(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509609274(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509610141(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509611102(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509611122(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509611135(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509611421(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509611606(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509611662(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509611969(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509612597(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509613207(1">
<meta property="og:image" content="http://yoursite.com/机器学习/blog/source/1509623343(1">
<meta property="og:updated_time" content="2017-11-03T03:19:07.059Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="决策树的理解与分析">
<meta name="twitter:description" content="本篇博客主要讲述决策树的构建和剪枝，分析ID3、C4.5和CART的差异，最后附上决策树的实现，下面开始我的表演 一、决策树介绍定义5.1 (决策树) ：分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node )和叶结点(leaf node)。内部结点表示一个特征或属性，叶结点表示">
<meta name="twitter:image" content="http://yoursite.com/机器学习/blog/source/1509607721(1">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/机器学习/决策树的理解与分析.html"/>





  <title>决策树的理解与分析 | YinHui's Bolg</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">YinHui's Bolg</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-首页">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-分类">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-标签">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-归档">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-关于">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
    
    <div class="post-block page">
      <header class="post-header">

	<h1 class="post-title" itemprop="name headline">决策树的理解与分析</h1>



</header>

      
      
      
      <div class="post-body">
        
        
          <p> 本篇博客主要讲述决策树的构建和剪枝，分析ID3、C4.5和CART的差异，最后附上决策树的实现，下面开始我的表演</p>
<h1 id="一、决策树介绍"><a href="#一、决策树介绍" class="headerlink" title="一、决策树介绍"></a>一、决策树介绍</h1><p><strong>定义5.1 (决策树) ：</strong>分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node )和叶结点(leaf node)。内部结点表示一个特征或属性，叶结点表示一个类。用决策树分类，从根结点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子结点；这时，每一个子结点对应着该特征的一个取值。如此递归地对实例进行测试并分配，直至达到叶结点。最后将实例分到叶结点的类中。</p>
<p>图中圆和方框分别表示内部结点和叶结点</p>
<p><img src="/机器学习/blog\source\1509607721(1" alt="1509607721(1)">.jpg)</p>
<p><strong>决策树与if-then规则</strong></p>
<p>可以将决策树看成一个if-then规则的集合，转换成if-then规则的过程：由决策树的根结点到叶结点的每一条路径构建一条规则；路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。决策树的路径或其对应的if-then规则集合具有一个重要的性质：互斥并且完备，每一个实例都被一条路径或一条规则所覆盖，而且只被一条路径或一条规则所覆盖。这里所谓覆盖是指实例的特征与路径上的特征一致或实例满足规则的条件。</p>
<p><strong>决策树与条件概率分布</strong></p>
<p>决策树还表示给定特征条件下类的条件概率分布。这一条件概率分布定义在特征空间的一个划分(partition)上，将特征空间划分为互不相交的单元(cell)或区域(region)，并在每个单元定义一个类的概率分布就构成了一个条件概率分布。</p>
<p>决策树的一条路径对应于划分中的一个单元。决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。条件概率分布可以表示为P(Y|X)，X取值于给定划分下单元的集合，Y取值于类的集合。各叶结点(单元)上的条件概率往往偏向某一个类，即属于某一类的概率较大。决策树分类时将该结点的实例强行分到条件概率大的那一类去。</p>
<h1 id="二、决策树的构造"><a href="#二、决策树的构造" class="headerlink" title="二、决策树的构造"></a>二、决策树的构造</h1><p>首先介绍用ID3和C4.5这两种方法构造决策树</p>
<p>ID3:根据信息增益进行构造</p>
<p>C4.5:根据最大增益比进行构造</p>
<p><strong>两者的区别</strong> : 对于一个特征来说，如果它的下面有非常多的label，就拿身份证来说，每一个人的身份证编号是不一样的，那么对于信息增益来说是最大的一个特征，这个时候你可以说身份证号是最好的特征吗？ 显然不能，进行一个人物分类的话，每个人的身份证号都不一样，你拿这个特征也就没有什么意义。因为就引入了C4.5采用信息增益比来进行特征选择。从而避免这类错误的产生。</p>
<p><strong>信息增益</strong>：特征A对训练数据集D的信息增益g(D,A)，定义为集合D的经验嫡H(D)与特征A给定条件下D的经验条件嫡H(D|A)之差，即</p>
<p><img src="/机器学习/blog\source\1509608563(1" alt="1509608563(1)">.jpg)</p>
<p><strong>信息增益比：</strong>特征A对训练数据集D的信息增益比gR(D,A)定义为其信息增益g(D,A)与训练数据集D的经验H(D)之比:</p>
<p><img src="/机器学习/blog\source\1509608634(1" alt="1509608634(1)">.jpg)</p>
<p>首先搬用李航老师的ID3和C4.5的算法</p>
<p>###<strong>ID3</strong></p>
<p><img src="/机器学习/blog\source\1509608944(1" alt="1509608944(1)">.jpg)</p>
<p><img src="/机器学习/blog\source\1509608972(1" alt="1509608972(1)">.jpg)</p>
<h3 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5**"></a>C4.5**</h3><p><img src="/机器学习/blog\source\1509608841(1" alt="1509608841(1)">.jpg)</p>
<p>直接这样知道步骤还是不了解具体怎么操作，那就直接来一个例子进行表示</p>
<p><img src="/机器学习/blog\source\1509609130(1" alt="1509609130(1)">.jpg)</p>
<p><img src="/机器学习/blog\source\1509609252(1" alt="1509609252(1)">.jpg)</p>
<p><img src="/机器学习/blog\source\1509609274(1" alt="1509609274(1)">.jpg)</p>
<p><strong>个人理解</strong>：首先会找一个信息增益或者信息增益比最大的一个特征作为自己分割的特征A，然后会分为两边，左边是“yes“为D1，右边是”no“为D2，开始分别对D1和D2进行再一次的分割，寻找最大增益比的特征，一定要注意这个时候如果最大增益比小于某个阀值，就会变成单节点，反之会进行继续分支状态。</p>
<h3 id="CART树的构造"><a href="#CART树的构造" class="headerlink" title="CART树的构造"></a>CART树的构造</h3><p><strong>CART</strong>:对于ID3和C4.5算法，他们主要是用于分类，但是CART树，不仅可以用于分类还可以用于回归，当进行回归时，采用平方误差最小化准则，对于分类树使用基尼指数最小化准则。 </p>
<p><strong>首先介绍最小二乘回归树生成算法</strong><img src="/机器学习/blog\source\1509610141(1" alt="1509610141(1)">.jpg)</p>
<p><strong>个人理解</strong>: 这里面是首先从你们选择空间中，选择一个值K作为切分点，然后把小于K的分为D1类，把大于K的分为D2类，开始求D1和D2的均方差。通过最小均方差和这个指标来找最优切分点。注意这个时候每一个支点的权重就是类中label的均值。   也就是对于D1来说他的权重就是对应label的均值，而且都是一样的。然后依次往下进行分枝操作。</p>
<p>下面是一个例子，可以作为参考</p>
<p><img src="/机器学习/blog\source\1509611102(1" alt="1509611102(1)">.jpg)</p>
<p><img src="/机器学习/blog\source\1509611122(1" alt="1509611122(1)">.jpg)</p>
<p><img src="/机器学习/blog\source\1509611135(1" alt="1509611135(1)">.jpg)</p>
<p>这道题是后面将来要讲的回归问题的提升树方法，但是原理是CART的回归问题，只是在每一步的操作中有一个求残差的运算。</p>
<p><strong>基于CART算法分类问题</strong></p>
<p>首先介绍基尼系数</p>
<p><img src="/机器学习/blog\source\1509611421(1" alt="1509611421(1)">.jpg)</p>
<p><img src="/机器学习/blog\source\1509611606(1" alt="1509611606(1)">.jpg)</p>
<p>来一道题进行详细解释</p>
<p><img src="/机器学习/blog\source\1509611662(1" alt="1509611662(1)">.jpg)</p>
<h1 id="三、决策树的剪枝"><a href="#三、决策树的剪枝" class="headerlink" title="三、决策树的剪枝"></a>三、决策树的剪枝</h1><p><strong>到了比较难理解的剪枝操作了，当你遇到与树相关的算法时候如XGboost、GBDT等，你就应该考虑两个方面，一个是树的构造过程，另一个就是树的剪枝过程</strong></p>
<p>首先介绍ID3和C4.5的剪枝，因为两者是一样的，所以可以放在一块啦</p>
<p><img src="/机器学习/blog\source\1509611969(1" alt="1509611969(1)">.jpg)</p>
<p><img src="/机器学习/blog\source\1509612597(1" alt="1509612597(1)">.jpg)</p>
<p><strong>理解</strong>：1、这是剪枝的核心公式，对于5.11来说，前面一部分是目标函数，后面一部分是L1正则。当a确定的时候，选择损失函数最小的模型。如果子树越大，往往与训练数据的拟合很好，但是模型的复杂度比较高。相反，子树越小，模型的复杂度就越低，但是往往与训练数据的拟好效果不好。对于T来说，当a越大的时候，可以减少模型的复杂度。一个极端情况下就是当a为0的时候，就相当于直接任由树的分枝，这样最后的模型虽然很好的拟合训练集但是不能很好的拟合测试集，也就是过拟合的现象。</p>
<p>2、一定要注意5.11的目标函数，这里面选用的是样本数*经验熵，在别处可能选择最小二乘法，绝对值法等，不能局限于此，</p>
<p>3、对于这里面为什么要乘上一个次数，下面是我找到的理解方式，感觉还不错。</p>
<p>首先问一个问题，Ht(T)代表的是什么？你肯定会说是经验熵，那什么是经验熵，你肯定会说是不确定度，到这里都没错，那这个不确定度是什么的不确定度呢？</p>
<p>我的理解是，这个叶子节点内部取k个类的不确定度，注意是节点【内部】的不确定度，每个叶子节点可以看作是独立的，既然是内部的事情，凭什么暴力的将各个内部的不确定度相加，我们至少到同一个级别的平台再加吧。</p>
<p>不知道你现在有没有感觉暴力的相加确实少了点什么，我的理解是，少了该节点的样本数，也就是Nt。不知道你有没有注意到，信息熵只用到了概率，而忽略了样本数，也就是只关注内部各个类别的比例，而不在乎整体数量的多少，那么乘以Nt后，我们把它叫做不确定次数，不确定程度就是不确定次数归一化后的东西。</p>
<p>既然都这么暴力了，就更暴力一点，你把Ht(T)理解成频率，Nt*Ht(T)对应地理解成次数吧。比如有A股B股两支股票，A股买了10次，赚了7次，B股买了100次，赚了50次，赚的频率分别是0.7和0.5，那么计算你投资的能力，是0.7+0.5更有意义呢还是7+50更有意义呢？我觉得7+50更有意义吧。</p>
<p>虽然不确定性和不确定次数并非频率和次数，但它们的相对关系就这么理解吧。</p>
<p><strong>开始讨论CARI算法的剪枝操作</strong></p>
<p><img src="/机器学习/blog\source\1509613207(1" alt="1509613207(1)">.jpg)</p>
<p>下里面是理解cart树剪枝的核心公式</p>
<p><img src="/机器学习/blog\source\1509623343(1" alt="1509623343(1)">.jpg)</p>
<p><strong>个人理解</strong>： 这里面的5.27已经是剪枝完毕后的表达式，也就是说原先的子结点已经变成当前的叶子节点，对于公式5.28，表示的是剪掉结点之前的损失函数。</p>

        
      </div>
      
      
      
    </div>
    
    
    
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/images.jpg"
                alt="yinhui" />
            
              <p class="site-author-name" itemprop="name">yinhui</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/yinhuil" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="yinhui@bupt.edu.cn" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#一、决策树介绍"><span class="nav-number">1.</span> <span class="nav-text">一、决策树介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#二、决策树的构造"><span class="nav-number">2.</span> <span class="nav-text">二、决策树的构造</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#C4-5"><span class="nav-number">2.0.1.</span> <span class="nav-text">C4.5**</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CART树的构造"><span class="nav-number">2.0.2.</span> <span class="nav-text">CART树的构造</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#三、决策树的剪枝"><span class="nav-number">3.</span> <span class="nav-text">三、决策树的剪枝</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yinhui</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  
  

  

  

  

</body>
</html>
